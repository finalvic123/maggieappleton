---
title: 'Where The Action Is'
subtitle: 'The Foundations of Embodied Interaction'
slug: where-the-action-is
author: 'Paul Dourish'
updated: 2021-01-28
published: true
type: ['book']
cover: './wheretheactionis.jpg'
---

[Paul Dourish](https://en.wikipedia.org/wiki/Paul_Dourish) takes us on a historical and philosophical exploration of how we interact with machines, and how our evolving understanding of embodied cognition is changing how we think about designing digital interfaces.

I first came across Dourish's work through his writings on [digital materiality](https://www.librarything.com/work/19893504), and his research on Ubiquitous Computing in [Divining a Digital Future](/diving-digital-future) with Geneieve Bell.

As I began reading more of the foundational literature around [Human-Computer Interaction](https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction) this year, I was surprised to see him pop up again. This book appears to be one of the modern classics of the field. Written in 2001, it holds up as a highly relevant and insightful exploration of how we should design computers that align with our embodied knowledge of the world.

---

## A History of Interaction design

Our notion of what a computer is, what it does, and how it works hasn't changed for decades.

We're still living with the legacy of a trade off made fifty years ago; computer processing time used to be enormously expensive. It was worth making humans transform their data and instructions into formal, rigid input languages that optimised for the machine's experience, rather than for the human experience. At the time, most computers were used for military or business calculations and no one minded too much.

We now have the odd contradiction that our machines have more power than we're able to leverage - 95% of the time they're doing basic tasks at low computational capacity. While we perch in front of them slowly deciding what we want to do next.

We're stuck in the historical paradigm of 'desktop computing' – the idea computers are a static workstation we plop in the corner of the room, and go to in order to execute specific tasks that occupy the whole of our attention.

The dream of Ubiquitous Computing tries to subvert this notion. Ubicomp is a paradigm of computing where our machines are embedded in everything around us. The point is to get us up and moving around in the world, and bring the computational power with us.

This was what we were promised with the 'internet of things,' which has so far turned out to be the internet of impractical, invasive surveillance objects.

Research institutes like [Dynamicland](https://dynamicland.org/) are reportedly exploring the idea of 'the room as a computer', but it all still seems like a  hypothetical prototype.

---

Dourish proposes the concept of **Embodied Interaction**

"Embodied Interaction is interaction with computer systems that occupy our world, a world of physical and social reality, and that exploit this fact in how they interact with us." (3)

Traditionally, computational systems are thought of as procedures - step by step models of sequential behaviour. The last two decades have seen us turn towards interaction. We are instead paying attention to the interplay of different components. An ecosystem of interlinked elements instead of a rote sequence of tasks.

The system focuses on many diverse elements with specific roles rather than generalised monolithic processes.

---

## The Four Phases of HCI History

Dourish presents four historical phases of HCI; electrical, symbolic, textual, and graphical

#### Electric

- Early computers had their logic physically wired into the circuits. You couldn't change the programme without resoldering connections.
- "the critical development in digital computing was that of the stored program computer... a machine whose operation is not directly encoded in its circuits, but rather is determined by a sequence of instructions held in its memory".
- Hardware and software were inherently and obviously tied together - wires, plugboards, patch cables were visible. Programming required an understanding of electrical design. There was very little distinction between the two "worlds" of hard/soft

#### Symbolic

- As computing matured, the way we communicated with them moved from numeric machine language to higher level symbolic language. This was the beginning of the programming language.
- First we developed assembly languishes which were one step removed from machine language. They still weren’t very portable between systems. We then developed FORTRAN and lisp which were one more level of abstraction. Interaction with computers became primarily symbolic at this stage - higher level programming languages are easier to write and debug. 
- “Symbolic interaction is a much more natural and intuitive form of interaction for us than the electronic form that had previously been necessary” 9

#### Textual

- Computer interaction moved into a primarily text-based medium. It created the dynamic where a user sits at a terminal entering commands and receiving responses - a Feedback Loop.
- “Although the notion of interaction with computers had important predecessors before this period such as Ivan Sutherland's hugely influential work on Sketchpad it was arguably from the paradigm of text-based dialogue that people drew the idea of interacting with the machine. ” 11

#### Graphical

- The move to graphical interfaces began with Ivan Sutherlands sketch pad in 1963, and was expanded by Alan Kays work on DynaBook at Xerox PARC
- “The move from textual to graphical interaction did not simply replace words with icons, but instead opened up whole new dimensions for interaction” 11
- Graphical interfaces took us from a one dimensional stream of characters into two dimensional space. Rather than dealing with a linear stream of words flowing up the screen, interfaces now involved managing space as well as information (arranging windows, focusing on multiple areas at once).
    - This allows us to arrange information in hierarchies of importance, and put content in our peripheral vision. “By placing them in the periphery, the application exploits my ability to focus on one area while passively attending to other activity in the edge of my visual field.” 12
- Graphical interfaces also allows us to use spatial reasoning and Spatial Memory - our ability to recognise patterns and Gestalt Principles help us organise information.
- Graphical interfaces allow us to create new Visual Metaphors, such as the Desktop Metaphor. “Information management tasks are based around a metaphorical model incorporating filing cabinets and trashcans” Digital Metaphors
    - “General Magic's Magic Cap interface, used a metaphorical depiction of an office featuring a desk (along with various desktop tools), a telephone, and a door open to a world outside; notetaking applications often feature graphical depictions of notebooks or index cards;” 13
- These kind of visual metaphors enable **direct manipulation of data**. Making data into discrete entities we can select, drag, drop, and delete. “From these separate elements, the designer builds an inhabited world in which users act.” 13
- “In 1981 Xerox's Star was the first personal computer to ship with the features of a graphical user interface as we recognize them today windows, menus, and a mouse and the Macintosh, three years later, was the first to ship in volume at an affordable price” 14
    - From that point on, mice and graphical interfaces were considered the obvious way we would interact with computers, thirty years later this is still the industry standard.

## Tangible and Social Computing

Tangible Computing is when we “distribute computation across a variety of devices, which are spread throughout the physical environment and are sensitive to their location and their proximity to other devices.” (15)

This is the same dream as Ubiquitous Computing and Internet of Things - baking computational logic into everyday objects

Another way to think about this is creating environments where the physical objects in the room act as the interfaces, rather than graphical interfaces and mice. This is the [Dynamicland](https://dynamicland.org/), Bret Victor version of the dream.

“Mice provide only simple information about movement in two dimensions, while in the everyday world we can manipulate many objects at once, using both hands and three dimensions to arrange the environment for our purposes and the activities at hand.” (16)

Social Computing is focused on “incorporating social understandings into the design of interaction itself. (16)
It focuses on interfaces as conversations, and draws on more social science/anthropological theory – trying to recreate social relations and social meaning in the computer interface.

Both Tangible Computing and Social Computing draw on our familiarity with the everyday world – they're "more than simple the metaphorical approach used in traditional User Interface Design."

Rather than focusing on imitating the physical world of objects in computers, they focus on bringing computing into our social, embodied experience of the world. **“They share an understanding that you cannot separate the individual from the world in which that individual lives and acts.”** (17-18)

In many ways the Human-Computer Interaction community is stuck in the world of Logical Positivism and Cartesian Dualism.

It's a view that “makes a strong separation between, on the one hand, the mind as the seat of consciousness and rational decision making, with an abstract model of the world that can be operated upon to form plans of action; and, on the other, the objective, external world as a largely stable collection of objects and events to be observed and manipulated according to the internal mental states of the individual” (18)

Dourish argues Embodiment is central to this approach. "Interaction is intimately connected with the settings in which it occurs" - in recent years interactions designers have realised the value of anthropological Ethnography to understand the environment and context of  interactions.

Early work in the field tried to create abstract models of the people they were designing for – hypothetical users – rather than exploring interaction design with real people in real contexts.

---

Human-Computer Interaction is not the only field recently captivated by Embodiment. Across disciplines, more consideration and attention is being paid to Phenomenology.
- Phenomenology is the study of how we perceive, experience, and act in the world around us. It's more concerned with our direct experiences than constructing abstract models about them.
- Phenomenology argues that the Mindbody Cartesian Dualism divide has no grounding in reality - "thinking does not occur separately from being and acting." (21)
